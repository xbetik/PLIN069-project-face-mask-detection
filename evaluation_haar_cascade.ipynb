{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f829237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from shapely.geometry import Polygon\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a2b4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnnotationIndex(prediction_box, annotation_boxes):\n",
    "    max_overlap = -1\n",
    "    max_overlap_index = -1\n",
    "    for i in range(len(annotation_boxes)):\n",
    "        overlap = calculate_iou(transformBox(prediction_box), transformBox(annotation_boxes[i]))\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            max_overlap_index = i\n",
    "    return max_overlap_index\n",
    "\n",
    "def transformBox(box):\n",
    "    x1 = box[0]\n",
    "    y1 = box[1]\n",
    "    \n",
    "    x2 = box[2]\n",
    "    y2 = box[3]\n",
    "    \n",
    "    return [[x1, y1], [x2, y1], [x2,y2], [x1,y2]]\n",
    "\n",
    "def calculate_iou(box_1, box_2):\n",
    "    poly_1 = Polygon(box_1)\n",
    "    poly_2 = Polygon(box_2)\n",
    "    iou = poly_1.intersection(poly_2).area / poly_1.union(poly_2).area\n",
    "    return iou\n",
    "\n",
    "def parse_annot(xml):\n",
    "    bbox = []\n",
    "    labels = []\n",
    "    \n",
    "    label_map = {\n",
    "        'without_mask': 1,\n",
    "        'with_mask': 2,\n",
    "        'mask_weared_incorrect': 3 \n",
    "    }\n",
    "    \n",
    "    tree = ET.parse(xml)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    for box in root.iter('object'):\n",
    "        bbox.append(\n",
    "               [\n",
    "                   int(box.find('bndbox/xmin').text),\n",
    "                   int(box.find('bndbox/ymin').text),\n",
    "                   int(box.find('bndbox/xmax').text),\n",
    "                   int(box.find('bndbox/ymax').text),\n",
    "               ]\n",
    "        )\n",
    "        labels.append(\n",
    "            label_map[box.find('name').text]\n",
    "        )\n",
    "    \n",
    "    return bbox, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3667179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE PATHS\n",
    "IMAGE_PATH = 'data/images'\n",
    "XML_PATH = 'data/annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d83f974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILES SORTED\n",
    "images = list(sorted(filter(lambda x: os.path.splitext(x)[1] == '.png', os.listdir(IMAGE_PATH))))\n",
    "xmls = list(sorted(filter(lambda x: os.path.splitext(x)[1] == '.xml', os.listdir(XML_PATH))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebc1ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAAR CASCADE MODEL\n",
    "face_model = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da4e42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTING IMAGES\n",
    "prediction_boxes = []\n",
    "for image in images:\n",
    "    img = cv2.imread(os.path.join(IMAGE_PATH, image))\n",
    "    img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n",
    "    pred_boxes = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4)\n",
    "    pred_boxes_rect = []\n",
    "    for (x,y,w,h) in pred_boxes:\n",
    "        pred_boxes_rect.append([x,y,x+w,y+h])\n",
    "    prediction_boxes.append(pred_boxes_rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "731b348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUND TRUTH EXTRACTED FROM ANNOTATIONS\n",
    "annot_boxes = []\n",
    "annot_labels = []\n",
    "annot_paths = []\n",
    "for xml in xmls:\n",
    "    bxs, lbls = parse_annot(os.path.join(XML_PATH, xml))\n",
    "    annot_boxes.append(bxs)\n",
    "    annot_labels.append(lbls)\n",
    "    annot_paths.append(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f19f1ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[310, 82, 366, 138], [9, 160, 68, 219]]\n",
      "[[79, 105, 109, 142], [185, 100, 226, 144], [325, 90, 360, 141]]\n"
     ]
    }
   ],
   "source": [
    "# PREDICTION OF THE FIRST IMAGE\n",
    "print(prediction_boxes[0])\n",
    "# GROUND TRUTH OF THE FIRST IMAGE\n",
    "print(annot_boxes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf3bad53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap: 0.491874487520049\n"
     ]
    }
   ],
   "source": [
    "# CALCULATING BOX OVERLAP WITH ANNOTATIONS\n",
    "overall_boxes = 0\n",
    "overlap = 0\n",
    "for i in range(len(prediction_boxes)):\n",
    "    for pred_box in prediction_boxes[i]:\n",
    "        j = getAnnotationIndex(pred_box, annot_boxes[i]) # get the closest annotation box\n",
    "        overlap += calculate_iou(transformBox(pred_box), transformBox(annot_boxes[i][j]))\n",
    "    overall_boxes += len(prediction_boxes[i])\n",
    "print(\"Overlap: \" + str(overlap / overall_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "447b9094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label overlap: 145/716\n",
      "Label prediction accuracy: 0.20251396648044692\n"
     ]
    }
   ],
   "source": [
    "# CALCULATING LABELS OVERLAP - MASK ON/OFF DETECTION BY ADDITIONAL VGG19 MODEL\n",
    "load_model = keras.models.load_model('masknet.h5')\n",
    "labels_dict={0:'with mask',1:'without mask'}\n",
    "color_dict={0:(0,255,0),1:(0,0,255)}\n",
    "correct = 0\n",
    "overall_labels = 0\n",
    "incorrect_detections = []\n",
    "for i in range(len(prediction_boxes)):\n",
    "    img = cv2.imread(os.path.join(IMAGE_PATH, images[i]))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    for pred_box in prediction_boxes[i]:\n",
    "        x = pred_box[0]\n",
    "        y = pred_box[1]\n",
    "        h = pred_box[2] - pred_box[0]\n",
    "        w = pred_box[3] - pred_box[1]\n",
    "        crop = img[y:y+h,x:x+w]\n",
    "        crop = cv2.resize(crop,(128,128))\n",
    "        crop = np.reshape(crop,[1,128,128,3])/255.0\n",
    "        result=load_model.predict(crop)\n",
    "        if result[0][0] > result[0][1]:\n",
    "            percent = round(result[0][0]*100,2)\n",
    "        else:\n",
    "            percent = round(result[0][1]*100,2)\n",
    "        face_label=np.argmax(result,axis=1)[0]\n",
    "        j = getAnnotationIndex(pred_box, annot_boxes[i])\n",
    "        if face_label == annot_labels[i][j]:\n",
    "            correct += 1\n",
    "        overall_labels +=1\n",
    "print(\"Label overlap: \" + str(correct) + \"/\" + str(overall_labels))\n",
    "print(\"Label prediction accuracy: \" + str(correct / overall_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
